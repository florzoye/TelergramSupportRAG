import os
import glob
import torch
import asyncio
from config import GIGACHAT_KEY, PDF_DIR, CHROMA_DIR, COLLECTION_NAME

from marker.converters.pdf import PdfConverter
from marker.models import create_model_dict
from marker.output import text_from_rendered

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_gigachat import GigaChat
from langchain_core.documents import Document

 
def process_pdfs_marker():
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF c –ø–æ–º–æ—â—å—é Marker OCR –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤ Chroma.
    """
    if not os.path.exists(PDF_DIR):
        print(f"‚ùå –ü–∞–ø–∫–∞ {PDF_DIR} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
        return False

    pdf_files = glob.glob(os.path.join(PDF_DIR, "*.pdf"))
    if not pdf_files:
        print("‚ö†Ô∏è –í –ø–∞–ø–∫–µ data –Ω–µ—Ç PDF —Ñ–∞–π–ª–æ–≤")
        return False

    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ PDF: {len(pdf_files)}")

    converter = PdfConverter(artifact_dict=create_model_dict())

    embed_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cuda 'if torch.cuda.is_available() else 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    vector_store = Chroma(
        collection_name=COLLECTION_NAME,
        persist_directory=CHROMA_DIR,
        embedding_function=embed_model
    )

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200,
        chunk_overlap=300,
        separators=["\n\n", "\n", ". ", " ", ""],
        length_function=len
    )

    for pdf_path in pdf_files:
        file_name = os.path.basename(pdf_path)
        print(f"\nüîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {file_name}")

        try:
            rendered = converter(pdf_path)
            text, _, _ = text_from_rendered(rendered)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Marker –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_name}: {e}")
            continue

        chunks = splitter.split_text(text)
        print(f"üì¶ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

        documents = [
            Document(
                page_content=chunk,
                metadata={
                    "source": file_name,
                    "chunk_id": i
                }
            )
            for i, chunk in enumerate(chunks)
        ]
        
        vector_store.add_documents(documents)
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    print("\nPDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ Chroma.")
    return True


async def aquery_resp(question: str, k: int = 3):
    """
    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)
    
    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç GigaChat –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    """
    embed_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    vector_store = Chroma(
        collection_name=COLLECTION_NAME,
        embedding_function=embed_model,
        persist_directory=CHROMA_DIR
    )

    llm = GigaChat(
        credentials=GIGACHAT_KEY,
        model="GigaChat-Pro",  
        verify_ssl_certs=False,
        temperature=0.2,
        max_tokens=2000
    )

    prompt = ChatPromptTemplate.from_template("""
        –¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ —Å–µ—Ä–≤–∏—Å–∞ –ú–û–°–ë–ò–†–ñ–ê. 
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

        –ü—Ä–∞–≤–∏–ª–∞:
        1. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ
        2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî —Å–∫–∞–∂–∏: "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É @support_mosbirzha"
        3. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É
        4. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —á—Ç–µ–Ω–∏—è
        5. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, —Å—Å—ã–ª–∞–π—Å—è –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

        –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
        {context}

        –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}

        –û—Ç–≤–µ—Ç:
    """)

    retrieved_docs = vector_store.similarity_search(question, k=k)
    
    if not retrieved_docs:
        return "‚ö†Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É @support_service"

    context_parts = []
    for i, doc in enumerate(retrieved_docs, 1):
        source = doc.metadata.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
        context_parts.append(f"[–î–æ–∫—É–º–µ–Ω—Ç {i}: {source}]\n{doc.page_content}")
    
    docs_content = "\n\n---\n\n".join(context_parts)

    try:
        message = await prompt.ainvoke({
            'question': question,
            'context': docs_content
        })
        
        answer = await llm.ainvoke(message)
        return answer.content
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GigaChat: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."


def query_resp_sync(question: str, k: int = 3):
    return asyncio.run(aquery_resp(question, k))


if __name__ == '__main__':
    success = True
    
    if success:
        print("\n" + "="*60)
        print("üéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã.")
        print("="*60)
        
        test_question =  "–ö–µ–º —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã?"
        answer = query_resp_sync(test_question)
        print(f"\nü§ñ –û—Ç–≤–µ—Ç: {answer}")